name: Test warehouse platform
on:
  workflow_dispatch:
    inputs:
      warehouse-type:
        type: choice
        required: true
        description: Type of warehouse platform
        options:
          - postgres
          - snowflake
          - bigquery
          - redshift
          - databricks
          - databricks_catalog
          - spark
      elementary-ref:
        type: string
        required: false
        description: Branch or tag to checkout for 'elementary' repository
      dbt-data-reliability-ref:
        type: string
        required: false
        description: Branch or tag to checkout for 'dbt-data-reliability' repository
      dbt-version:
        type: string
        required: false
        description: dbt's version to test with

  workflow_call:
    inputs:
      warehouse-type:
        type: string
        required: true
      elementary-ref:
        type: string
        required: false
      dbt-data-reliability-ref:
        type: string
        required: false
      dbt-version:
        type: string
        required: false

env:
  BRANCH_NAME: ${{ github.head_ref || github.ref_name }}
  TESTS_DIR: ${{ github.workspace }}/dbt-data-reliability/integration_tests

jobs:
  test:
    runs-on: ubuntu-20.04
    concurrency:
      group: tests-${{ inputs.warehouse-type }}-${{ github.head_ref || github.ref_name }}
      cancel-in-progress: true
    steps:
      - name: Checkout Elementary
        uses: actions/checkout@v3
        with:
          repository: elementary-data/elementary
          path: elementary
          ref: ${{ inputs.elementary-ref }}

      - name: Checkout dbt package
        uses: actions/checkout@v3
        with:
          path: dbt-data-reliability
          ref: ${{ inputs.dbt-data-reliability-ref }}

      - name: Start Postgres
        if: inputs.warehouse-type == 'postgres'
        working-directory: ${{ env.TESTS_DIR }}
        run: docker-compose up -d postgres

      - name: Write dbt profiles
        env:
          CI_PROFILES_YML: ${{ secrets.CI_PROFILES_YML }}
        run: |
          mkdir -p ~/.dbt
          UNDERSCORED_REF_NAME=$(echo "${{ env.BRANCH_NAME }}" | head -c 32 | sed "s/-/_/g")
          echo "$CI_PROFILES_YML" | base64 -d | sed "s/<SCHEMA_NAME>/dbt_$UNDERSCORED_REF_NAME/g" > ~/.dbt/profiles.yml

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8.17"

      - name: Install Spark requirements
        if: inputs.warehouse-type == 'spark'
        run: sudo apt-get install python-dev libsasl2-dev gcc

      - name: Install dbt
        run: pip install --pre
          "dbt-core${{ inputs.dbt-version && format('=={0}', inputs.dbt-version) }}"
          "dbt-${{ (inputs.warehouse-type == 'databricks_catalog' && 'databricks') || inputs.warehouse-type }}${{ inputs.dbt-version && format('<={0}', inputs.dbt-version) }}"

      - name: Install Elementary
        run: pip install "./elementary[${{ (inputs.warehouse-type == 'databricks_catalog' && 'databricks') || inputs.warehouse-type }}]"

      - name: Install E2E project deps
        working-directory: ${{ env.TESTS_DIR }}
        run: dbt deps

      - name: Test
        working-directory: ${{ env.TESTS_DIR }}/integration_tests/tests
        run: |
          pip install -r ../requirements.txt
          dbt deps --project-dir=../dbt_project
          py.test -n8 -vvv --target "${{ inputs.warehouse-type }}" --junit-xml=test-results.xml

      - name: Surface failing tests
        if: always()
        uses: pmeier/pytest-results-action@main
        with:
          path: ${{ env.TESTS_DIR }}/integration_tests/tests/test-results.xml
          summary: true
          display-options: fEX
          fail-on-empty: true
