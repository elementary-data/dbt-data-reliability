name: Test warehouse platform
on:
  workflow_dispatch:
    inputs:
      warehouse-type:
        type: choice
        required: true
        description: Type of warehouse platform
        options:
          - postgres
          - snowflake
          - bigquery
          - redshift
          - databricks_catalog
          - spark
          - athena
          - trino
          - clickhouse
          - dremio
      elementary-ref:
        type: string
        required: false
        description: Branch or tag to checkout for 'elementary' repository
      dbt-data-reliability-ref:
        type: string
        required: false
        description: Branch or tag to checkout for 'dbt-data-reliability' repository
      dbt-version:
        type: string
        required: false
        default: "latest_official"
        description: dbt's version to test with

  workflow_call:
    inputs:
      warehouse-type:
        type: string
        required: true
      elementary-ref:
        type: string
        required: false
      dbt-data-reliability-ref:
        type: string
        required: false
      dbt-version:
        type: string
        default: "latest_official"
        required: false

env:
  BRANCH_NAME: ${{ github.head_ref || github.ref_name }}
  TESTS_DIR: ${{ github.workspace }}/dbt-data-reliability/integration_tests

jobs:
  # PRs from forks require approval
  check-if-requires-approval:
    runs-on: ubuntu-latest
    outputs:
      requires_approval: ${{ steps.set-output.outputs.requires_approval }}
    steps:
      - name: Set requires approval output
        id: set-output
        run: |
          if [[ "${{ github.event_name }}" =~ ^pull_request && "${{ github.event.pull_request.head.repo.full_name }}" != "${{ github.repository }}" ]]; then
            echo "requires_approval=true" >> $GITHUB_OUTPUT
          else
            echo "requires_approval=false" >> $GITHUB_OUTPUT
          fi

  test:
    runs-on: ubuntu-latest
    needs: [check-if-requires-approval]
    environment: ${{ (needs.check-if-requires-approval.outputs.requires_approval == 'true' && 'elementary_test_env') || '' }}
    concurrency:
      # This is what eventually defines the schema name in the data platform.
      group: tests_${{ inputs.warehouse-type }}_dbt_${{ inputs.dbt-version }}_${{ github.head_ref || github.ref_name }}
      cancel-in-progress: true
    steps:
      - name: Checkout Elementary
        uses: actions/checkout@v4
        with:
          repository: elementary-data/elementary
          path: elementary
          ref: ${{ inputs.elementary-ref }}

      - name: Checkout dbt package
        uses: actions/checkout@v4
        with:
          path: dbt-data-reliability
          ref: ${{ inputs.dbt-data-reliability-ref }}

      - name: Start Postgres
        if: inputs.warehouse-type == 'postgres'
        working-directory: ${{ env.TESTS_DIR }}
        run: docker compose up -d postgres

      - name: Start Trino
        if: inputs.warehouse-type == 'trino'
        working-directory: ${{ env.TESTS_DIR }}
        run: docker compose -f docker-compose-trino.yml up -d

      - name: Start Clickhouse
        if: inputs.warehouse-type == 'clickhouse'
        working-directory: ${{ env.TESTS_DIR }}
        run: docker compose up -d clickhouse

      - name: Start Dremio
        if: inputs.warehouse-type == 'dremio'
        working-directory: ${{ env.TESTS_DIR }}
        run: docker compose -f docker-compose-dremio.yml up -d

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"
          cache: "pip"

      - name: Install Spark requirements
        if: inputs.warehouse-type == 'spark'
        run: sudo apt-get install python-dev libsasl2-dev gcc

      - name: Install compatible databricks connector (not limited in older dbt-databricks versions)
        if: startsWith(inputs.warehouse-type, 'databricks') && inputs.dbt-version < '1.7.0'
        run: pip install databricks-sql-connector==2.9.3

      - name: Install dbt
        if: ${{ inputs.dbt-version != 'fusion' }}
        run:
          pip install${{ (inputs.dbt-version == 'latest_pre' && ' --pre') || '' }}
          "dbt-core${{ (!startsWith(inputs.dbt-version, 'latest') && format('=={0}', inputs.dbt-version)) || '' }}"
          "dbt-${{ (inputs.warehouse-type == 'databricks_catalog' && 'databricks') || (inputs.warehouse-type == 'spark' && 'spark[PyHive]') || (inputs.warehouse-type == 'athena' && 'athena-community') || inputs.warehouse-type }}${{ (!startsWith(inputs.dbt-version, 'latest') && format('~={0}', inputs.dbt-version)) || '' }}"

      - name: Install dbt-fusion
        if: inputs.dbt-version == 'fusion'
        run: |
          curl -fsSL https://public.cdn.getdbt.com/fs/install/install.sh | sh -s -- --update

      - name: Install Elementary
        run: pip install "./elementary[${{ (inputs.warehouse-type == 'databricks_catalog' && 'databricks') || inputs.warehouse-type }}]"

      - name: Write dbt profiles
        env:
          PROFILES_YML: ${{ (inputs.dbt-version == 'fusion' && secrets.CI_PROFILES_YML_FUSION) || secrets.CI_PROFILES_YML }}
        run: |
          mkdir -p ~/.dbt
          DBT_VERSION=$(echo "${{ inputs.dbt-version }}" | sed 's/\.//g')
          UNDERSCORED_REF_NAME=$(echo "${{ inputs.warehouse-type }}_dbt_${DBT_VERSION}_${BRANCH_NAME}" | awk '{print tolower($0)}' | head -c 40 | sed "s/[-\/]/_/g")
          echo "$PROFILES_YML" | base64 -d | sed "s/<SCHEMA_NAME>/dbt_pkg_$UNDERSCORED_REF_NAME/g" > ~/.dbt/profiles.yml

      - name: Install dependencies
        working-directory: ${{ env.TESTS_DIR }}
        run: |
          ${{ (inputs.dbt-version == 'fusion' && '~/.local/bin/dbt') || 'dbt' }} deps --project-dir dbt_project
          ln -sfn ${{ github.workspace }}/dbt-data-reliability dbt_project/dbt_packages/elementary
          pip install -r requirements.txt

      - name: Check DWH connection
        working-directory: ${{ env.TESTS_DIR }}
        run: |
          ${{ (inputs.dbt-version == 'fusion' && '~/.local/bin/dbt') || 'dbt' }} debug -t "${{ inputs.warehouse-type }}"

      - name: Test
        working-directory: "${{ env.TESTS_DIR }}/tests"
        run: py.test -n8 -vvv --target "${{ inputs.warehouse-type }}" --junit-xml=test-results.xml --html=detailed_report_${{ inputs.warehouse-type }}_dbt_${{ inputs.dbt-version }}.html --self-contained-html --clear-on-end ${{ (inputs.dbt-version == 'fusion' && '--runner-method fusion') || '' }}

      - name: Upload test results
        if: always()
        uses: pmeier/pytest-results-action@main
        with:
          path: ${{ env.TESTS_DIR }}/tests/test-results.xml
          summary: true
          display-options: fEX
          fail-on-empty: true

      - name: Upload HTML report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: detailed_report_${{ inputs.warehouse-type }}_dbt_${{ inputs.dbt-version }}
          path: ${{ env.TESTS_DIR }}/tests/detailed_report_${{ inputs.warehouse-type }}_dbt_${{ inputs.dbt-version }}.html
